{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv(override = True)\n",
    "OPENAI_API_KEY=os.getenv('OPENAI_API_KEY')\n",
    "TAVILY_API_KEY=os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import langgraph\n",
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(max_results=2)\n",
    "repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def python_repl(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "def get_stock_price(ticker: str) -> float:\n",
    "    \"\"\"Gets a stock price from Yahoo Finance.\n",
    "\n",
    "    Args:\n",
    "        ticker: ticker str\n",
    "    \"\"\"\n",
    "    # \"\"\"This is a tool for getting the price of a stock when passed a ticker symbol\"\"\"\n",
    "    stock = yf.Ticker(ticker)\n",
    "    return stock.info['previousClose']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import SystemMessage, HumanMessage  # or from langchain.chat_models import ...\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "tools = [get_stock_price,search,python_repl]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def reasoner(state):\n",
    "    query = state[\"query\"]\n",
    "    messages = state[\"messages\"]\n",
    "    # System message\n",
    "    sys_msg = SystemMessage(content='''You are a Expert Financial advisor tasked with using {search}, the {get_stock_price} for getting latest news to figure out current public sentiment using \n",
    "#                             this news.and Give solid Financial Advice also considering the sentiment that you evaluated on set of inputs.I need specific advice depending upon public sentiment and not any general response''')\n",
    "    message = HumanMessage(content=query)\n",
    "    messages.append(message)\n",
    "    result = [llm_with_tools.invoke([sys_msg] + messages)]\n",
    "    return {\"messages\":result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"State of the graph.\"\"\"\n",
    "    query: str\n",
    "    finance: str\n",
    "    final_answer: str\n",
    "    # intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "from typing import Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition # this is the checker for the\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "# Graph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add Nodes\n",
    "workflow.add_node(\"reasoner\", reasoner)\n",
    "workflow.add_node(\"tools\", ToolNode(tools)) # for the tools\n",
    "\n",
    "# Add Edges\n",
    "workflow.add_edge(START, \"reasoner\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"reasoner\",\n",
    "    # If the latest message (result) from node reasoner is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from node reasoner is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"reasoner\")\n",
    "react_graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = react_graph.invoke(\n",
    "    {\"query\": \"should i invest in google\", \"messages\": []},\n",
    "    config={\"recursion_limit\": 100}  # Adjust the limit based on your needs\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
